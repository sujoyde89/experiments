{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from PIL import Image, ImageFile\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['motorbike', 'aeroplane', 'dog', 'bottle', 'boat', 'pottedplant', 'cow', 'horse', 'person', 'car', 'cat', 'diningtable', 'bus', 'bird', 'bicycle', 'chair']\n"
     ]
    }
   ],
   "source": [
    "parent_dir = './dataset'\n",
    "sub_dirs = next(os.walk(parent_dir))[1]\n",
    "print (sub_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 16 folders containing images from the above mentioned categories.  \n",
    "Now we will create a dataframe containing category, file_name, and encoding of the catgeory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_details = []\n",
    "for sub_dir in sub_dirs:\n",
    "    dir_path = join(parent_dir, sub_dir)\n",
    "    files = [f for f in listdir(dir_path) if isfile(join(dir_path, f))]\n",
    "    for file in files:\n",
    "        file_detail = {}\n",
    "        file_detail['class'] = sub_dir\n",
    "        file_detail['path'] = join(parent_dir, sub_dir, file)\n",
    "        if os.path.getsize(file_detail['path'])>0:\n",
    "            files_details.append(file_detail)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "lbl = LabelEncoder()\n",
    "df = pd.DataFrame(files_details)\n",
    "df['class_encoded'] = lbl.fit_transform(df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>path</th>\n",
       "      <th>class_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>motorbike</td>\n",
       "      <td>./dataset/motorbike/2008_008246.jpg</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>motorbike</td>\n",
       "      <td>./dataset/motorbike/2008_007739.jpg</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>motorbike</td>\n",
       "      <td>./dataset/motorbike/2008_002926.jpg</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>motorbike</td>\n",
       "      <td>./dataset/motorbike/2008_007485.jpg</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>motorbike</td>\n",
       "      <td>./dataset/motorbike/2008_007054.jpg</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                 path  class_encoded\n",
       "0  motorbike  ./dataset/motorbike/2008_008246.jpg             13\n",
       "1  motorbike  ./dataset/motorbike/2008_007739.jpg             13\n",
       "2  motorbike  ./dataset/motorbike/2008_002926.jpg             13\n",
       "3  motorbike  ./dataset/motorbike/2008_007485.jpg             13\n",
       "4  motorbike  ./dataset/motorbike/2008_007054.jpg             13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((793, 3), 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df['class'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aeroplane      50\n",
       "bicycle        50\n",
       "cow            50\n",
       "car            50\n",
       "dog            50\n",
       "chair          50\n",
       "person         50\n",
       "bus            50\n",
       "motorbike      50\n",
       "cat            50\n",
       "bottle         50\n",
       "diningtable    50\n",
       "horse          50\n",
       "bird           50\n",
       "boat           50\n",
       "pottedplant    43\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, transform):\n",
    "        self.data = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data.loc[idx, 'path']\n",
    "        image = Image.open(img_name)\n",
    "        image = self.transform(image)\n",
    "        label = torch.tensor(self.data.loc[idx, 'class_encoded'])\n",
    "        return {'image': image, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "num_classes = 16\n",
    "batch_size = 16\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = { \n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=12).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>path</th>\n",
       "      <th>class_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bottle</td>\n",
       "      <td>./dataset/bottle/2008_002864.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chair</td>\n",
       "      <td>./dataset/chair/2008_001841.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chair</td>\n",
       "      <td>./dataset/chair/2008_007742.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>car</td>\n",
       "      <td>./dataset/car/2008_001208.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pottedplant</td>\n",
       "      <td>./dataset/pottedplant/2008_005214.jpg</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         class                                   path  class_encoded\n",
       "0       bottle       ./dataset/bottle/2008_002864.jpg              4\n",
       "1        chair        ./dataset/chair/2008_001841.jpg              8\n",
       "2        chair        ./dataset/chair/2008_007742.jpg              8\n",
       "3          car          ./dataset/car/2008_001208.jpg              6\n",
       "4  pottedplant  ./dataset/pottedplant/2008_005214.jpg             15"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((634, 3), (159, 3))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, valid = train_test_split(df, test_size=0.2)\n",
    "train.reset_index(drop = True, inplace = True)\n",
    "valid.reset_index(drop = True, inplace = True)\n",
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>path</th>\n",
       "      <th>class_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pottedplant</td>\n",
       "      <td>./dataset/pottedplant/2008_000275.jpg</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chair</td>\n",
       "      <td>./dataset/chair/2008_001563.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bus</td>\n",
       "      <td>./dataset/bus/2008_008343.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>person</td>\n",
       "      <td>./dataset/person/2008_004307.jpg</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pottedplant</td>\n",
       "      <td>./dataset/pottedplant/2008_005111.jpg</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         class                                   path  class_encoded\n",
       "0  pottedplant  ./dataset/pottedplant/2008_000275.jpg             15\n",
       "1        chair        ./dataset/chair/2008_001563.jpg              8\n",
       "2          bus          ./dataset/bus/2008_008343.jpg              5\n",
       "3       person       ./dataset/person/2008_004307.jpg             14\n",
       "4  pottedplant  ./dataset/pottedplant/2008_005111.jpg             15"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>path</th>\n",
       "      <th>class_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chair</td>\n",
       "      <td>./dataset/chair/2008_005616.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cow</td>\n",
       "      <td>./dataset/cow/2008_000905.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bird</td>\n",
       "      <td>./dataset/bird/2008_004973.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>motorbike</td>\n",
       "      <td>./dataset/motorbike/2008_006944.jpg</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dog</td>\n",
       "      <td>./dataset/dog/2008_002536.jpg</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                 path  class_encoded\n",
       "0      chair      ./dataset/chair/2008_005616.jpg              8\n",
       "1        cow        ./dataset/cow/2008_000905.jpg              9\n",
       "2       bird       ./dataset/bird/2008_004973.jpg              2\n",
       "3  motorbike  ./dataset/motorbike/2008_006944.jpg             13\n",
       "4        dog        ./dataset/dog/2008_002536.jpg             11"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(train, transform=image_transforms['train'])\n",
    "valid_dataset = ImageDataset(valid, transform=image_transforms['valid'])\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "val_data_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_loader), len(val_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_inputs = model.fc.in_features\n",
    " \n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(fc_inputs, 256),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(256, 64),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(64, 16)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]\n",
      "Loss: 1.7937, Accuracy: 0.22\n",
      "Cohen Kappa: 0.16\n",
      "Epoch [2/10]\n",
      "Loss: 1.3470, Accuracy: 0.48\n",
      "Cohen Kappa: 0.44\n",
      "Epoch [3/10]\n",
      "Loss: 1.5588, Accuracy: 0.56\n",
      "Cohen Kappa: 0.53\n",
      "Epoch [4/10]\n",
      "Loss: 0.9333, Accuracy: 0.61\n",
      "Cohen Kappa: 0.58\n",
      "Epoch [5/10]\n",
      "Loss: 1.3213, Accuracy: 0.59\n",
      "Cohen Kappa: 0.56\n",
      "Epoch [6/10]\n",
      "Loss: 2.3609, Accuracy: 0.64\n",
      "Cohen Kappa: 0.61\n",
      "Epoch [7/10]\n",
      "Loss: 1.5542, Accuracy: 0.65\n",
      "Cohen Kappa: 0.62\n",
      "Epoch [8/10]\n",
      "Loss: 0.8756, Accuracy: 0.68\n",
      "Cohen Kappa: 0.66\n",
      "Epoch [9/10]\n",
      "Loss: 2.0108, Accuracy: 0.66\n",
      "Cohen Kappa: 0.63\n",
      "Epoch [10/10]\n",
      "Loss: 1.7019, Accuracy: 0.66\n",
      "Cohen Kappa: 0.64\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_data_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    total_correct_preds = 0\n",
    "    total_samples = 0\n",
    "    total_loss = 0\n",
    "    correct_labels = []\n",
    "    predicted_labels = []\n",
    "    for i, image_label in enumerate(train_data_loader):\n",
    "        image, label = image_label['image'], image_label['label']\n",
    "        #image = image.cuda(), label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss_list.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total = label.size(0)\n",
    "        predicted = outputs.max(1)[1]\n",
    "        correct = (predicted == label).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "        total_correct_preds += correct\n",
    "        total_samples += total\n",
    "        total_loss += loss.item() * total\n",
    "        \n",
    "        correct_labels.extend(label.data.cpu().numpy())\n",
    "        predicted_labels.extend(outputs.max(1)[1].cpu().numpy())\n",
    "        \n",
    "    print('Epoch [{}/{}]'.format(epoch + 1, num_epochs))\n",
    "    print('Loss: {:.4f}, Accuracy: {:.2f}'.format(loss.item(),(total_correct_preds / total_samples)))\n",
    "    print('Cohen Kappa: {:.2f}'.format(cohen_kappa_score(correct_labels, predicted_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.629\n",
      "Test cohen score: 0.602\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    total_correct_preds = 0\n",
    "    total_samples = 0\n",
    "    correct_labels = []\n",
    "    predicted_labels = []\n",
    "    for image_label in val_data_loader:\n",
    "        image, label = image_label['image'], image_label['label']\n",
    "        outputs = model(image)\n",
    "\n",
    "        # Class with the highest probability is our predicted class\n",
    "        equality = (label.data == outputs.max(1)[1])\n",
    "        # Accuracy is number of correct predictions divided by all predictions\n",
    "        correct_preds = equality.type_as(torch.FloatTensor()).sum()\n",
    "        samples = len(equality)\n",
    "        total_correct_preds += correct_preds\n",
    "        total_samples += samples\n",
    "\n",
    "        correct_labels.extend(label.data.cpu().numpy())\n",
    "        predicted_labels.extend(outputs.max(1)[1].cpu().numpy())\n",
    "\n",
    "    print(\"Test accuracy: {:.3f}\".format(total_correct_preds/total_samples))\n",
    "    print(\"Test cohen score: {:.3f}\".format(cohen_kappa_score(correct_labels, predicted_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_inputs = model.fc.in_features\n",
    " \n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(fc_inputs, 256),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(256, 64),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(64, 16)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]\n",
      "Loss: 3.0182, Accuracy: 0.09\n",
      "Cohen Kappa: 0.03\n",
      "Epoch [2/10]\n",
      "Loss: 2.9316, Accuracy: 0.09\n",
      "Cohen Kappa: 0.02\n",
      "Epoch [3/10]\n",
      "Loss: 3.0758, Accuracy: 0.07\n",
      "Cohen Kappa: 0.00\n",
      "Epoch [4/10]\n",
      "Loss: 2.9017, Accuracy: 0.08\n",
      "Cohen Kappa: 0.02\n",
      "Epoch [5/10]\n",
      "Loss: 2.6756, Accuracy: 0.08\n",
      "Cohen Kappa: 0.02\n",
      "Epoch [6/10]\n",
      "Loss: 2.9589, Accuracy: 0.09\n",
      "Cohen Kappa: 0.02\n",
      "Epoch [7/10]\n",
      "Loss: 2.8108, Accuracy: 0.07\n",
      "Cohen Kappa: 0.01\n",
      "Epoch [8/10]\n",
      "Loss: 2.9570, Accuracy: 0.07\n",
      "Cohen Kappa: 0.01\n",
      "Epoch [9/10]\n",
      "Loss: 2.8201, Accuracy: 0.07\n",
      "Cohen Kappa: 0.01\n",
      "Epoch [10/10]\n",
      "Loss: 2.9215, Accuracy: 0.09\n",
      "Cohen Kappa: 0.03\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_data_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    total_correct_preds = 0\n",
    "    total_samples = 0\n",
    "    total_loss = 0\n",
    "    correct_labels = []\n",
    "    predicted_labels = []\n",
    "    for i, image_label in enumerate(train_data_loader):\n",
    "        image, label = image_label['image'], image_label['label']\n",
    "        #image = image.cuda(), label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss_list.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total = label.size(0)\n",
    "        predicted = outputs.max(1)[1]\n",
    "        correct = (predicted == label).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "        total_correct_preds += correct\n",
    "        total_samples += total\n",
    "        total_loss += loss.item() * total\n",
    "        \n",
    "        correct_labels.extend(label.data.cpu().numpy())\n",
    "        predicted_labels.extend(outputs.max(1)[1].cpu().numpy())\n",
    "        \n",
    "    print('Epoch [{}/{}]'.format(epoch + 1, num_epochs))\n",
    "    print('Loss: {:.4f}, Accuracy: {:.2f}'.format(loss.item(),(total_correct_preds / total_samples)))\n",
    "    print('Cohen Kappa: {:.2f}'.format(cohen_kappa_score(correct_labels, predicted_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.113\n",
      "Test cohen score: 0.050\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    total_correct_preds = 0\n",
    "    total_samples = 0\n",
    "    correct_labels = []\n",
    "    predicted_labels = []\n",
    "    for image_label in val_data_loader:\n",
    "        image, label = image_label['image'], image_label['label']\n",
    "        outputs = model(image)\n",
    "\n",
    "        # Class with the highest probability is our predicted class\n",
    "        equality = (label.data == outputs.max(1)[1])\n",
    "        # Accuracy is number of correct predictions divided by all predictions\n",
    "        correct_preds = equality.type_as(torch.FloatTensor()).sum()\n",
    "        samples = len(equality)\n",
    "        total_correct_preds += correct_preds\n",
    "        total_samples += samples\n",
    "\n",
    "        correct_labels.extend(label.data.cpu().numpy())\n",
    "        predicted_labels.extend(outputs.max(1)[1].cpu().numpy())\n",
    "\n",
    "    print(\"Test accuracy: {:.3f}\".format(total_correct_preds/total_samples))\n",
    "    print(\"Test cohen score: {:.3f}\".format(cohen_kappa_score(correct_labels, predicted_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.alexnet(pretrained='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model.classifier[6].in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 256),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(256, 64),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(64, 16)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]\n",
      "Loss: 2.8005, Accuracy: 0.07\n",
      "Cohen Kappa: 0.00\n",
      "Epoch [2/10]\n",
      "Loss: 2.7743, Accuracy: 0.05\n",
      "Cohen Kappa: -0.02\n",
      "Epoch [3/10]\n",
      "Loss: 2.8031, Accuracy: 0.07\n",
      "Cohen Kappa: 0.01\n",
      "Epoch [4/10]\n",
      "Loss: 2.7830, Accuracy: 0.05\n",
      "Cohen Kappa: -0.02\n",
      "Epoch [5/10]\n",
      "Loss: 2.7813, Accuracy: 0.05\n",
      "Cohen Kappa: -0.01\n",
      "Epoch [6/10]\n",
      "Loss: 2.7885, Accuracy: 0.07\n",
      "Cohen Kappa: 0.00\n",
      "Epoch [7/10]\n",
      "Loss: 2.7673, Accuracy: 0.06\n",
      "Cohen Kappa: -0.01\n",
      "Epoch [8/10]\n",
      "Loss: 2.8003, Accuracy: 0.06\n",
      "Cohen Kappa: -0.01\n",
      "Epoch [9/10]\n",
      "Loss: 2.7799, Accuracy: 0.08\n",
      "Cohen Kappa: 0.01\n",
      "Epoch [10/10]\n",
      "Loss: 2.7988, Accuracy: 0.06\n",
      "Cohen Kappa: -0.01\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_data_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    total_correct_preds = 0\n",
    "    total_samples = 0\n",
    "    total_loss = 0\n",
    "    correct_labels = []\n",
    "    predicted_labels = []\n",
    "    for i, image_label in enumerate(train_data_loader):\n",
    "        image, label = image_label['image'], image_label['label']\n",
    "        #image = image.cuda(), label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss_list.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total = label.size(0)\n",
    "        predicted = outputs.max(1)[1]\n",
    "        correct = (predicted == label).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "        total_correct_preds += correct\n",
    "        total_samples += total\n",
    "        total_loss += loss.item() * total\n",
    "        \n",
    "        correct_labels.extend(label.data.cpu().numpy())\n",
    "        predicted_labels.extend(outputs.max(1)[1].cpu().numpy())\n",
    "        \n",
    "    print('Epoch [{}/{}]'.format(epoch + 1, num_epochs))\n",
    "    print('Loss: {:.4f}, Accuracy: {:.2f}'.format(loss.item(),(total_correct_preds / total_samples)))\n",
    "    print('Cohen Kappa: {:.2f}'.format(cohen_kappa_score(correct_labels, predicted_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.031\n",
      "Test cohen score: 0.000\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    total_correct_preds = 0\n",
    "    total_samples = 0\n",
    "    correct_labels = []\n",
    "    predicted_labels = []\n",
    "    for image_label in val_data_loader:\n",
    "        image, label = image_label['image'], image_label['label']\n",
    "        outputs = model(image)\n",
    "\n",
    "        # Class with the highest probability is our predicted class\n",
    "        equality = (label.data == outputs.max(1)[1])\n",
    "        # Accuracy is number of correct predictions divided by all predictions\n",
    "        correct_preds = equality.type_as(torch.FloatTensor()).sum()\n",
    "        samples = len(equality)\n",
    "        total_correct_preds += correct_preds\n",
    "        total_samples += samples\n",
    "\n",
    "        correct_labels.extend(label.data.cpu().numpy())\n",
    "        predicted_labels.extend(outputs.max(1)[1].cpu().numpy())\n",
    "\n",
    "    print(\"Test accuracy: {:.3f}\".format(total_correct_preds/total_samples))\n",
    "    print(\"Test cohen score: {:.3f}\".format(cohen_kappa_score(correct_labels, predicted_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
